{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f592b469",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "from Managers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacf710e",
   "metadata": {},
   "source": [
    "# Harris Corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16a1e706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectHarrisCorners(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = np.float32(gray)\n",
    "    dst  = cv2.cornerHarris(gray, 2, 23, 0.04)\n",
    "    \n",
    "    image[dst > 0.01 * dst.max()] = (0, 0, 255)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ce0a8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = CameraManager('Harris Corners', cv2.VideoCapture(0), detectHarrisCorners).addCloseCallback()\n",
    "cam.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63867c14",
   "metadata": {},
   "source": [
    "# Sift Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e031a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "def detectSIFTFeatures(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    keypoints, descriptor = sift.detectAndCompute(gray, None)\n",
    "    \n",
    "    return cv2.drawKeypoints(image, keypoints, image, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS, color=(51,163,236))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67f09335",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = CameraManager('SIFT Features', cv2.VideoCapture(0), detectSIFTFeatures).addCloseCallback()\n",
    "cam.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c1d741",
   "metadata": {},
   "source": [
    "# Surf Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b47e4a4",
   "metadata": {},
   "source": [
    "This algortihm is now patented. It is not even that good though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c1ebbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "surf = cv2.xfeatures2d.SURF_create(4000)\n",
    "\n",
    "def detectSurfFeatures(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    keypoints, descriptor = surf.detectAndCompute(gray, None)\n",
    "    \n",
    "    return cv2.drawKeypoints(image, keypoints, image, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS, color=(51,163,236))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a1529a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV(4.5.0) D:\\Users\\berta\\OpenCV Git\\opencv_contrib-4.5.0\\modules\\xfeatures2d\\src\\surf.cpp:1029: error: (-213:The function/feature is not implemented) This algorithm is patented and is excluded in this configuration; Set OPENCV_ENABLE_NONFREE CMake option and rebuild the library in function 'cv::xfeatures2d::SURF::create'\n",
      "\n",
      "Error! Could not process one frame.\n"
     ]
    }
   ],
   "source": [
    "cam = CameraManager('SURF Features', cv2.VideoCapture(0), detectSurfFeatures).addCloseCallback()\n",
    "cam.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035c7336",
   "metadata": {},
   "source": [
    "# Matching Orb Features between Images using Brute Force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dcf362c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cap = DummyCapture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6886869",
   "metadata": {},
   "outputs": [],
   "source": [
    "orb = cv2.ORB_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30495906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orbMatchTwoFrames(frames):\n",
    "    img1, img2 = frames\n",
    "    kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "    kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "    \n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(des1, des2)\n",
    "    matches = sorted(matches, key=lambda x:x.distance)\n",
    "    \n",
    "    return cv2.drawMatches(img1, kp1, img2, kp2, matches[:40], img2, flags=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "018f1097",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = CameraManagerStereo('Show Orb Matching', \n",
    "                          [cv2.VideoCapture(0), dummy_cap], orbMatchTwoFrames\n",
    ").addCloseCallback()\n",
    "cam.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0e3844",
   "metadata": {},
   "source": [
    "# Matching Orb Features between Images using KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0735cb",
   "metadata": {},
   "source": [
    "We can do an approximate matching between two images. We can see that a lot of lines are not horizontal. A custom matching algorithm could be made to enusure that only approximately horizontal images are made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40688da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def orbMatchTwoFramesKNN(frames, nr_neighbours=2):\n",
    "    img1, img2 = frames\n",
    "    kp1, des1 = orb.detectAndCompute(img1, None)\n",
    "    kp2, des2 = orb.detectAndCompute(img2, None)\n",
    "    \n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des1, des2, k=nr_neighbours)\n",
    "\n",
    "    return cv2.drawMatchesKnn(img1, kp1, img2, kp2, matches[:40], img2, flags=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8faafb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = CameraManagerStereo('Show Orb Matching KNN', \n",
    "                          [cv2.VideoCapture(0), dummy_cap], orbMatchTwoFramesKNN\n",
    ").addCloseCallback()\n",
    "cam.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76015556",
   "metadata": {},
   "source": [
    "This kind of flann based feature matching is also used to match images to a similiar image in a database."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
